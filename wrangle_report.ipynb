{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter data wrangling report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. The Twitter archive is great, but it only contains very basic tweet information. Additional gathering, then assessing and cleaning is required for \"Wow!\"-worthy analyses and visualizations.\n",
    "\n",
    "Specific Notes: \n",
    "- You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "- You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Enhanced Twitter Archive\n",
    "\n",
    "The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything. One column the archive does contain though: each tweet's text, which I used to extract rating, dog name, and dog \"stage\" (i.e. doggo, floofer, pupper, and puppo) to make this Twitter archive \"enhanced.\" Of the 5000+ tweets, I have filtered for tweets with ratings only (there are 2356)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Additional Data via the Twitter API\n",
    "\n",
    "Back to the basic-ness of Twitter archives: retweet count and favorite count are two of the notable column omissions. Fortunately, this additional data can be gathered by anyone from Twitter's API. Well, \"anyone\" who has access to data for the 3000 most recent tweets, at least."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Image Predictions File\n",
    "\n",
    "Ran every image in the WeRateDogs Twitter archive through a neural network that can classify breeds of dogs*. The results: a table full of image predictions (the top three only) alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Gathering data source 1 - image prediction`:\n",
    "    Get Tweet image prediction by downloading from url programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Gathering data source 2 - twitter_archive_enhanced`:\n",
    "    This file is given and just read from the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Gathering data source 3 - tweet_json`: \n",
    "    Did not chose API connection, instead directly get the tweet_json.txt file and copying the API extraction code. However, these data can be access via API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the dataset including two steps:\n",
    "1. visulize the dataset(give the data an visual inspect)\n",
    "2. programmatic assessment(including look at dataset info, look at basic statistical describe of each columns)\n",
    "3. Data issue found: Describe and document the issue found in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For these three dataset, I found below issues:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Issue Summary\n",
    "\n",
    "#### Quality Issue:\n",
    "`twitter_archive_enhanced`:\n",
    "- Has extra rows that tweet_json doesn't have, which is not useful for further analysis\n",
    "- Delete unnecessary columns with lots of missing values and the retweet rows to be removed, since retweets are essentially duplicates of the actual tweets. \n",
    "- timestamp should be convert to datetime format\n",
    "- None values in dog names change to unknown\n",
    "- Filter tweets after 2017-08-01\n",
    "- Remove incorrect ratings (ratings that are not 10 as denumerator)\n",
    "- Ratings with decimal values incorrectly extracted\n",
    "- Merge multiple dog stages and delete the rows with multiple stages\n",
    "\n",
    "`image_predictions`:\n",
    "- img_num change to category data type\n",
    "- Deduplicate the dataset, there are duplicated rows\n",
    "- Adding final prediction column, based on the logic of p1, p2, p3 prediction accuracy and confident interval\n",
    "\n",
    "\n",
    "#### Tidyness Issue:\n",
    "- Dog stage columns are not useable and need to be transformed into other formart(use pd.melt)\n",
    "- Merge three datasets\n",
    "- Delete unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data including three steps:\n",
    "    1. Define the issue\n",
    "    2. Code to clean data\n",
    "    3. Test to make sure code works well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this study, all the data quality issue and tidyness issue are being addressed and tested successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
